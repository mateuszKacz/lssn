{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp:\n",
    "    '''Wielowarstwowy perceptron (1 warstwa ukryta)'''\n",
    "    def __init__(self, n_in, n_out, n_hid):\n",
    "        \n",
    "        # liczba neuronów w kolejnych warstwach\n",
    "        self.n_in=n_in\n",
    "        self.n_hid=n_hid\n",
    "        self.n_out=n_out\n",
    "\n",
    "        # stany neuronów\n",
    "        self.S_in=zeros(n_in+1)\n",
    "        self.S_hid=zeros(n_hid)\n",
    "        self.S_out=zeros(n_out)\n",
    "        self.S_in[-1]=1\n",
    "\n",
    "        # pola lokalne\n",
    "        self.h_hid=zeros(n_hid)\n",
    "        self.h_out=zeros(n_out)\n",
    "\n",
    "        # wagi połączeń\n",
    "        self.W_ih=zeros((n_in+1,n_hid))\n",
    "        self.W_ho=zeros((n_hid,n_out))\n",
    "\n",
    "        # delty\n",
    "        self.dW_ih=zeros((n_in+1,n_hid))\n",
    "        self.dW_ho=zeros((n_hid,n_out))\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.W_ih = normal(0, 1/sqrt(self.n_hid), self.W_ih.shape)\n",
    "        self.W_ho = normal(0, 1/sqrt(self.n_out), self.W_ho.shape)\n",
    "        \n",
    "        \n",
    "    def f(self, x):\n",
    "        '''Funkcja aktywacji'''\n",
    "#         return 1/(1+exp(-x))\n",
    "#         return (tanh(x/2)+1)/2\n",
    "        return maximum(x,0) # ReLU - rectified linear unit\n",
    "\n",
    "    def Df(self, x):\n",
    "        '''Pochodna funkcji aktywacji'''\n",
    "#         y=self.f(x)\n",
    "#         return y*(1-y)\n",
    "#         return cosh(x)**-1/4\n",
    "        return heaviside(x,0)\n",
    "\n",
    "    def feed(self, inp):\n",
    "        '''Przekazuje wektor danych do warstwy wejściowej'''\n",
    "        self.S_in[:self.n_in]=inp\n",
    "\n",
    "    def forward(self):\n",
    "        '''Propaguje sygnał poprzez kolejne warstwy sieci'''\n",
    "        self.h_hid = self.S_in @ self.W_ih\n",
    "        self.S_hid = self.f(self.h_hid)\n",
    "        self.h_out = self.S_hid @ self.W_ho\n",
    "        self.S_out = self.f(self.h_out)\n",
    "        \n",
    "    def diff(self, p):\n",
    "        return self.trainData[p,self.n_in:] - self.S_out\n",
    "\n",
    "    def error(self,p):\n",
    "        return sum(self.diff(p)**2)/2\n",
    "    \n",
    "    def setTrainData(self,data):\n",
    "        '''Zapamiętuje referencję do wektorów uczących'''\n",
    "        self.trainData=data\n",
    "\n",
    "    def eval(self,inp):\n",
    "        self.feed(inp)\n",
    "        self.forward()\n",
    "        return self.S_out\n",
    "\n",
    "\n",
    "    def train(self, eta):\n",
    "        '''Jedna epoka.'''\n",
    "    \n",
    "        Er=0\n",
    "        p_num=self.trainData.shape[0]\n",
    "\n",
    "        self.dW_ih.fill(0)\n",
    "        self.dW_ho.fill(0)\n",
    "\n",
    "        for p in range(p_num):\n",
    "            self.feed(self.trainData[p,:self.n_in])\n",
    "            self.forward()\n",
    "        \n",
    "            self.delta_out = self.Df(self.h_out)*self.diff(p)\n",
    "            self.dW_ho += outer(self.S_hid, self.delta_out)\n",
    "            self.delta_hid = self.Df(self.h_hid)*(self.W_ho @ self.delta_out)\n",
    "            self.dW_ih += outer(self.S_in, self.delta_hid)\n",
    "\n",
    "            Er+=self.error(p)\n",
    "\n",
    "        self.W_ih+=eta*self.dW_ih\n",
    "        self.W_ho+=eta*self.dW_ho\n",
    "        return Er   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
